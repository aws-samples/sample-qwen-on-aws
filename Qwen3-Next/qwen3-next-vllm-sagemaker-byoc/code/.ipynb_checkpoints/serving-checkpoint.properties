engine=Python
option.entryPoint=model.py
option.model_id=Qwen/Qwen3-Next-80B-A3B-Instruct
option.tensor_parallel_degree=4
option.max_model_len=100000
option.dtype=auto
option.gpu_memory_utilization=0.9
option.enforce_eager=false
option.max_num_seqs=32
option.served_model_name=qwen3-next
option.tokenizer_mode=auto
option.trust_remote_code=true
option.task=text-generation
option.load_format=auto
option.quantization=None
option.max_num_batched_tokens=16384
option.enable_prefix_caching=false
option.disable_chunked_prefill=true
option.disable_log_stats=false
option.swap_space=4
option.kv_cache_dtype=auto
option.revision=main
option.block_size=16
option.seed=0
option.response_role=assistant
option.speculative_config={"method": "qwen3_next_mtp", "num_speculative_tokens": 2}
option.tool_call_parser=hermes
option.enable_auto_tool_choice=true

